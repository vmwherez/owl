> 	The 'plus plus' kind of referring to moving into C++ as well as continuing in signal processing.
>  Will P's book. VA Filter Design Book. 




[[Taylor Series]]
[[Fourier Series]]
[[wavelets]]
## [[ThinkDSP]]

[[DFT]]
[[DCT]]

#### [[VA Filter Design]]
[obsidian://open?vault=notes&file=spicy_noodles%2Fpdf%2FVAFilterDesign_2.1.2.pdf](obsidian://open?vault=notes&file=spicy_noodles%2Fpdf%2FVAFilterDesign_2.1.2.pdf)


## [[designing audio plugins]]





https://ccrma.stanford.edu/~jos/sitemap.html


https://ccrma.stanford.edu/courses/320c-spring-2022/
# Assignment 1.5: Adding Faust to JUCE

https://ccrma.stanford.edu/courses/320c-spring-2022/assignments/15/


### Mathematics of the DFT

https://colab.research.google.com/github/khiner/notebooks/blob/master/mathematics_of_the_dft/chapter_1_introduction_to_the_dft.ipynb#scrollTo=t7IhlrHVQM7b

https://ccrma.stanford.edu/~jos/mdft/DFT_Definition.html

https://ccrma.stanford.edu/~jos/mdft/Fourier_Transforms_Continuous_Discrete_Time_Frequency.html

https://karlhiner.com/jupyter_notebooks/mathematics_of_the_dft

## wave
## 

https://github.com/pparmin/wavemaker

---


---
https://github.com/danigb/rust-synth

https://github.com/nbennett320/dawesome/tree/b26e464794cfd3720a7010957f01eee3b620a1ed

## µ+

```
Project µ introduced the ability to place the unified study track into my 'vim notebook'.
```

```
I guess Designing Audio Effect Plugins in C++ is more of a 'workshop' kind of thing.
```

https://github.com/danigb/rust-synth
https://github.com/nbennett320/dawesome/tree/b26e464794cfd3720a7010957f01eee3b620a1ed


## Adding Faust DSP Support to Your JUCE Plug-ins

- https://musinf.univ-st-etienne.fr/lac2017/pdfs/08_C_B_137208.pdf
- https://faust.grame.fr/doc/tutorials/index.html
- https://ccrma.stanford.edu/~rmichon/faustTutorials/#setting-up-your-development-environment
- https://github.com/rustaudio
- https://rust-embedded.github.io/book/interoperability/rust-with-c.html
- https://github.com/maxwellpollack/juce-plugin-ci
- https://github.com/mbrucher/JUCE.cmake
- https://github.com/elk-audio/faust-vst-template
- https://www.youtube.com/watch?v=Yom9E-67bdI

## Designing Audio Effect Plugins in C++  
Will C Pirckle.

*Some of this might live in workshop, some in math. Stuff about CMake is in tools. My naming convention is still a little ad hoc.*

- [ ]  1.2 Fundamentals of Audio Signal Processing
- [ ] 1.2.1 Acquisition of Audio Samples
- [ ] 1.3 Reconstruction of the Analog Signal  

```
[1] From new book, 
Designing Audio Effect Plugins in C++
first couple of chapters dumped:

Chapter 1: 
1.1 Using This Book 
1.2 Fundamentals of Audio Signal Processing 
1.2.1 Acquisition of Audio Samples 
1.3 Reconstruction of the Analog Signal 
1.4 Numerical Representation of Audio Data 
1.5 Analytical DSP Test Signals 
1.5.1 DC and Step (0 Hz) 
1.5.2 Nyquist 
1.5.3 ½ Nyquist 
1.5.4 ¼ Nyquist 
1.5.5 Impulse 
1.6 Signal Processing Algorithms 
1.6.1 Bookkeeping 
1.6.2 The One-Sample Delay 
1.6.3 Multiplication With a Scalar Value 
1.6.4 Addition and Subtraction 
1.6.5 Some Algorithm Examples and Difference Equations 
1.6.5.1 Gain, Attenuation and Phase Inversion   
1.7 1st Order Feed-Forward and Feedback Algorithms 
1.8 Bibliography 
 Chapter 2: Anatomy of an Audio Plugin
  2.1 Plugin Packaging: Dynamic-Link Libraries (DLLs) 
  2.2 The Plugin Description: Simple Strings   
  2.2.1 The Plugin Description: Features and Options 
  2.3 Initialization: Defining the Plugin Parameter Interface 
  2.3.1 Initialization: Defining Channel I/O Support 
  2.3.2 Initialization: Sample Rate Dependency 
  2.4 Processing: Preparing for Audio Streaming 
  2.4.1 Processing: Audio Signal Processing (DSP) 
  2.5 Mixing Parameter Changes With Audio Processing   
  2.5.1 Plugin Variables and Plugin Parameters 
  2.5.2 Parameter Smoothing   
  2.5.3 Pre and Post-Processing Updates 
  2.5.4 VST3 Sample Accurate Updates 
  2.5.5 Multi-Threaded Software 
  2.6 Monolithic Plugin Objects 
  2.7 Bibliography 
  
  Pirkle, Will C.. Designing Audio Effect Plugins in C++ (p. viii). Taylor and Francis. Kindle Edition.
```


## 1.5.2 Nyquist

---
## Faust

Faust Homepage - https://faust.grame.fr/

## Vult

Vult - https://github.com/vult-dsp/vult

## Will Pirkle's Stuff

ASPik - https://github.com/willpirkleaudio/ASPiK

https://www.willpirkle.com


## CCRMA: The Synthesis ToolKit in C++ (STK)
By Perry R. Cook and Gary P. Scavone, 1995--2019
http://ccrma.stanford.edu/software/stk/.
.

## FAuSt

**[JULIUS O. SMITH III](http://ccrma.stanford.edu/~jos)** 
[*Center for Computer Research in Music and Acoustics (CCRMA)*](http://ccrma.stanford.edu/)

https://ccrma.stanford.edu/~jos/filters/Book_Series_Overview.html

https://ccrma.stanford.edu/~jos/mdft/

https://ccrma.stanford.edu/~jos/mdft/DFT_Math_Outline.html

https://ccrma.stanford.edu/~jos/pasp/Freeverb.html

https://ccrma.stanford.edu/~jos/pasp/Example_Schroeder_Reverberators.html

https://learning.oreilly.com/library/view/designing-audio-effect/9780240825151/chapter02.xhtml

---

https://www.dsprelated.com/freebooks/pasp/Freeverb.html

---

https://github.com/jatinchowdhury18/distortion-rs

https://github.com/jatinchowdhury18/AnalogTapeModel

---

https://github.com/elk-audio/faust-vst-template

https://www.youtube.com/watch?v=Yom9E-67bdI

## Adding Faust DSP Support to Your JUCE Plug-ins

https://musinf.univ-st-etienne.fr/lac2017/pdfs/08_C_B_137208.pdf

https://faust.grame.fr/doc/tutorials/index.html

https://ccrma.stanford.edu/~rmichon/faustTutorials/#setting-up-your-development-environment

https://github.com/rustaudio

https://rust-embedded.github.io/book/interoperability/rust-with-c.html

https://github.com/maxwellpollack/juce-plugin-ci

https://github.com/mbrucher/JUCE.cmake

---

https://www.musicdsp.org/en/latest/

https://github.com/ddiakopoulos/MoogLadders

https://github.com/thestk/rtaudio

https://github.com/LancePutnam/Gamma

https://www.youtube.com/watch?v=m7xYX8f8A7Y

https://github.com/mtytel/mopo/blob/master/src/distortion.cpp

https://github.com/ffAudio/PluginGuiMagic

https://github.com/FigBug/Gin

https://docs.microsoft.com/en-us/cpp/cpp/header-files-cpp?view=vs-2019



https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust/


- https://learning.oreilly.com/library/view/designing-audio-effect/9780240825151/chapter02.xhtml

---

- https://www.dsprelated.com/freebooks/pasp/Freeverb.html

---

- https://github.com/jatinchowdhury18/distortion-rs
- https://github.com/jatinchowdhury18/AnalogTapeModel

---





---

- https://www.musicdsp.org/en/latest/
- https://github.com/ddiakopoulos/MoogLadders
- https://github.com/thestk/rtaudio
- https://github.com/LancePutnam/Gamma
- https://www.youtube.com/watch?v=m7xYX8f8A7Y
- https://github.com/mtytel/mopo/blob/master/src/distortion.cpp
- https://github.com/ffAudio/PluginGuiMagic
- https://github.com/FigBug/Gin
- https://docs.microsoft.com/en-us/cpp/cpp/header-files-cpp?view=vs-2019

### teropa
#TeroParviainen
#javascript


https://teropa.info
https://teropa.info/loop/#/systemdefinition
https://teropa.info/blog/2016/07/28/javascript-systems-music.html I really wanted to play with this when I saw it in 2016
https://teropa.info/blog/2017/01/23/terry-rileys-in-c.html
https://teropa.info/blog/2016/07/28/javascript-systems-music.html


## Laurie Spiegel



[![](https://web.archive.org/web/20220629172535im_/http://retiary.org/ls/gifs_ls/laurie_fiddling_116k.jpg)](https://web.archive.org/web/20220629172535fw_/http://retiary.org/ls/misc_pages/kyle_biog.html)
**Laurie Spiegel**   
  
Laurie Spiegel is one of those rare composers in whom head and heart, left brain and right brain, logic and intuition, merge and even exchange roles.Though she is one of the highest-tech computer composers in America, Spiegel is also a lutenist and banjo player, and sees the computer as a new kind of folk instrument. She makes her most intuitive-sounding and melodic music from mathematical algorithms, and her most complex computerized textures by ear and in search of a desired mood. Form and emotion are as difficult to separate in her music as they are in that of her idol, J.S. Bach.   
  
Spiegel was born in Chicago where in her teens she played guitar, banjo, and mandolin, and through them cultivated a devout philosophy of amateur music making. After receiving a degree in the social sciences, she returned to music. Having taught herself notation, she studied classic guitar and composition privately in London, then baroque and renaissance lute at Julliard, and composition with Jacob Druckman and Vincent Persichetti.   
  
Having worked with analog synthesizers since 1969, she sought out the greater compositional control which digital computers could provide and wrote interactive compositional software at Bell Labs from 1973-79. She later founded New York University's Computer Music Studio, and became famous in rock music circles for her music software for personal computers, especially MusicMouse. MusicMouse's built-in musical logic allows even nonliterate musicians to create music in either tonal or atonal styles by hitting the computer's keys and moving its mouse. Distilled from centuries of musical practice, MusicMouse's statistical possibilities are enormous, and make any amateur feel suddenly in control of myriad elements. Still, the key to using MusicMouse to make successful music lies in what one does beyond the software, in both musical performance and electronic orchestration.   
  
Despite her innovative involvement with technology, Spiegel the composer has never been dominated by Spiegel the computer technician. Her music from the 70s used compositional algorithms (in one case a realization of Kepler's "Harmony of the Planets", included in the Voyager spacecraft's record _Sounds of Earth_) to generate music in an accessible, minimalist vein. Some of that music was captured on her record on the Philo label, _The Expanding Universe_, containing works from 1974-6.   
  
But in the early 80s, Spiegel distanced herself from the downtown New York scene that she had helped create, complaining that the new music scene's general direction was toward an "expansion of the collection of tools and techniques available to make music (useful, but not as the central content of a work)". "For me," she more recently explained, "music is a way to deal with the extreme intensity of moment to moment conscious existence." Since breaking away, Spiegel has lived as one of New York's most independent musicians, supporting herself by her software and circulating her music privately.   
  
Those who fell in love with the folk like melodies and early algorithms of _The Expanding Universe_ may be surprised to hear how much darker and more complex Spiegel's recent music has become. "Minimalism" may still aptly describe the slow movement of pitch in these pieces _(Unseen Worlds)_, but it gives no hint of their complex timbres, glacial momentum,and cathartic climaxes. Such vibrant, expressive music could only have come from a composer who put her intuition and imagination first, yet who had the immense technical know-how needed to meet the challenges they posed.   
  
_Notes by [Kyle Gann](https://web.archive.org/web/20220629180839/http://home.earthlink.net/~kgann/index.html) for the cd **Unseen Worlds**_   
(Kyle Gann is a composer and music critic for the Village Voice.)

**The Visual Arts**   
   
**_Drawing -_**   
  
I've always loved drawing and doing art, even just pencil drawing, [colored pencils](https://web.archive.org/web/20220629180259fw_/http://retiary.org/ls/ls_visual_art/color_drawings.html) or [plain old ordinary ones](https://web.archive.org/web/20220629180259fw_/http://retiary.org/ls/ls_visual_art/pencil_drawings.html). I thought of going to art school instead of college, but ended up deciding not to get "educated"in visual art in any way that might mess up my enjoyment of the process by getting ego or money mixed up in it. (I sometimes wish I'd been equally smart about how I pursued music, but I was drawn to music with such force I couldn't have manifested the same resistence.)   
  
**_Computer Graphics and Video -_**   
  
After beginning to use them for music, I realized that the computer is a sort of Rossetta Stone for the arts. Techniques learned for music (programming, learning to describe abstract structures and processes in artificial languages) are applicable to alternative sensory modalities of input/output in an unprecedented way. (All the guitar chops in the world won't help you much with a paint brush.)   
  
So, of course, I wrote myself what's now called a "paint" program (one of the first, at [Bell Labs](https://web.archive.org/web/20220629180259fw_/http://retiary.org/ls/btl/btl.html) in 1974), then made lots of [still images](https://web.archive.org/web/20220629180259fw_/http://retiary.org/ls/btl/ls_btl_art.html) using it. I also [interfaced it](https://web.archive.org/web/20220629180259fw_/http://retiary.org/ls/writings/vampire.html) with time structuring software I was already using for music composition, and was able to generate output to video and film in the following years.   
  
Recently I've begun to very much enjoy [photography](https://web.archive.org/web/20220629180259/http://flickr.com/photos/27810605@N06/) again, which I had begun as a kid but not done much of the past couple of decades.   
  
See a few of my [videos on YouTube](https://web.archive.org/web/20220629180259/http://www.youtube.com/MusicMouse) and my [photographs on Flickr](https://web.archive.org/web/20220629180259/http://flickr.com/photos/27810605@N06/).   

![](https://web.archive.org/web/20220629180259im_/http://retiary.org/ls/gifs_ls/energy2_melted.gif)   
  
© Laurie Spiegel. All Rights Reserved



 https://web.archive.org/web/20220629172347fw_/http://retiary.org/ls/programs.html 
- Laurie Spiegel - https://web.archive.org/web/20220629172531/http://retiary.org/ls/index.html




Laurie Spiegel working at the DDP-224 computer console at [Bell Telephone Labs](https://web.archive.org/web/20220629180413/http://www.bell-labs.com/history/) in the mid-1970s.   
_Photograph by Emmanuel Ghent, digital rendering by Laurie Spiegel_

## The Early Computer Arts at Bell Labs

Societal attitudes toward computers have changed greatly since our early days of trying for the first time to use computers to make various kinds of art (images, music, etc) a mere couple of decades ago. Whereas [back then](https://web.archive.org/web/20220629180413/http://retiary.org/ls/writings/cmj_then_vs_now.html) we were most commonly accused of attempting to completely dehumanize the arts, at this point there has become such widespread acceptance of these machines in the arts that there is now a good bit of interest in how this came to be.

This subsite will be expanded as my time permits, hopefully with contributed information from others (right now I have mostly just my own to draw on). Meanwhile, here are a few files I've already uploaded for you to browse:

-   A quick description of the [GROOVE](https://web.archive.org/web/20220629180413fw_/http://retiary.org/ls/btl/groove_quick_description.html) hybrid computer music system, 
    
-   pictures of [Emmanuel Ghent](https://web.archive.org/web/20220629180413fw_/http://retiary.org/ls/btl/ghent.gif) and [me](https://web.archive.org/web/20220629180413fw_/http://retiary.org/ls/btl/ls_in_max_lab.gif) (photographs taken by each other) wrestling with the hardware end of GROOVE's digital-analog hybrid architecture, 
    
-   some of the "[computer art](https://web.archive.org/web/20220629180413fw_/http://retiary.org/ls/btl/ls_btl_art.html)" I made at BTL during the 1970s. 
    
-   for a sense of the software interface I coded up to co-compose music and image or to make images that changed over time with the same kinds of structures that music has, my description of my [VAMPIRE](https://web.archive.org/web/20220629180413/http://retiary.org/ls/writings/vampire.html), my "Video And Music Program for Interactive Realtime Exploration", 
    
-   a simple explanation of how I sometimes used [information theory in composing](https://web.archive.org/web/20220629180413/http://retiary.org/ls/writings/info_theory_music.html) some of my music, this theory having been developed at the Labs, 
    
-   [Ken Knowlton](https://web.archive.org/web/20220629180413/http://www.kenknowlton.com/pages/04portrait.htm)'s remembrances of that period at the lab.
    
-   and [Max Mathews](https://web.archive.org/web/20220629180413fw_/http://retiary.org/ls/btl/max_statement.html)' own summary of his ground-breaking computer music work.
    

---

### An Information Theory Based Compositional Model

by Laurie Spiegel   
May, 1997

Put simply, information theory[1] is a mathematical theory of how to optimize a signal for communication in a noisy channel and of how communication degrades in such a medium. My piece on the accompanying LMJ cd is an example of its musical use.

To understand its application, let's start simply by putting a basic melodic pattern of 16 pitches into a digital array from which they can be played as notes. On first hearing, it's pure information. Every note we hear is informative, unpredictable, not just confirming something heard before. Its entropy, or informational content, is high.

But it falls far short of being a musical composition. It lacks development, evolution, and form. Our sequence offers little pleasure and contains no means of conveying emotions through sameness and difference, anticipation, prediction, surprise, disappointment, reassurance, or return.

Next, repeat the pattern cyclicly. At first this feels more musical. But the longer we listen, the more boring it becomes. Our sense of anticipation grows as we wait for something more, for change, uncertainty, the unpredictable, the resumption of information. The average entropy over the whole "block" of this listening session continues to dwindle toward the infinitesimal with each additional repetition. It's completely redundant, providing nothing unforeseen. The data is reassuringly hard to miss or forget, but we're certain what each note will be before we hear it.

To make it function better as music, we can introduce noise, which cannot be predicted and therefore acts as information in this context by increasing the amount of uncertainty each note will resolve. We use it to raise the number of possible values each note could have from only one to 2, 3, several, or many. We program the random corruption of our pattern during its travel from safe unchanging storage array through the communications channels of software and sound to our ears and minds. It's more interesting now with greater entropy, but is it more musical?

Random corruption should not be confused with random generation. Many note generating algorithms just plug random number streams into aspects of sound. But even with elaborate filter logic, that's not the same. Noise is the replacement of explicitly defined information with random data at random times. It's the degradation of otherwise fully intelligible signal. In this case, we are using random noise in place of information to increase entropy, to counteract redundency. This is outside of information theory but works because music is self-referential and sensory rather than symbolic.

The next refinement of our model is based on the fact that not all components of a signal are equally vulnerable to noise. For example, quieter sounds are lost to noise before loud ones. The probability of losing any specific predetermined sound to noise depends on its individual characteristics and context, and this provides us with powerful compositional variables. These variables in sum give us direct control of musical entropy, of the amount of uncertainty that hearing each sound will resolve.

The logic for selecting sounds vulnerable to corruption is critical but simple, and for it, we continue to draw on information theory. Sounds containing less signal energy are more likely to be affected by noise, and conversely. In other words, it makes sense in light of nature that the quietest and shortest notes, and those poorest in harmonic (timbral) content (redundancy within spectrum), should be corrupted first. These are the notes most easily lost to radio static or environmental noise at a concert, and in traditional repertoire also tend to be less structurally important, like passing tones on weak beats versus downbeats or pedal tones.

Based on these various noise vulnerability factors, we can now create a master variable representing overall momentary entropy, and control it interactively in real time, perhaps turning a knob to increase or decrease the probability that each next pitch of our unchanging cycle will be randomly replaced by some other value. We can use this entropy variable to sculpt overall musical form, to manipulate tensions and expectations and thereby the listener's emotions. We can now compose more meaningfully.

If man has evolved music as a communications medium in a noisy world, it must embody reflections of other structures, including cognitive processes and natural sounds, and have built deeply into it's nature, among the many things that make it work, compensations for natural phenomena which would otherwise diminish its effectiveness. These must also be phenomena that follow natural laws, in this case Shannon's[2,3].

We should also consider the nature of the noise affecting our signal. Not all noise is created equal nor does it exist in a vacuum as a Platonic Gaussian ideal. Much of the "noise" that affects our ability to communicate is generated by something that makes sense in some other context. I consider randomness a relativistic phenomenon: any signal, no matter how internally consistent or meaningful it is within its own context, may be perceived as random noise relative to some other coherent signal.

So our noise source may be, for example, some other musical pattern, or even our own played asynchronous to itself, producing interference patterns which may exhibit their own structure, or it might be a weighted or contoured spectrum of data like a Fractal sequence or 1/f noise.

In order to generalize this compositional model beyond computer use, we might ask whether there actually is any such process as composition, and if so, what it is. We can ask how, whether, and why we distinguish the original creation of musical materials from their transformation. Instances of transformation abound, in arrangements, orchestrations, and variations, and there exist many standard techniques whereby new music is derived from old[4]. Instances of original creation also appear to be abundant, but are they really?

I would suggest that even in the inner realm of auditory imagination, what we interpret as spontaneous generation may be just the transformation of previously experienced material as it moves within the human perceptual and cognitive systems, informational channels in which it could well be vulnerable to the noise of our many coexistent memories and thoughts. If so, the application of information theory to music could have much broader productive implications.

I first learned about information theory at Bell Labs, Murray Hill in the 1970s, and found it an excellent and very musically useful model. I used FORTRAN implementations of such logic to compose computer-generated works throughout the 1970's and found it aesthetically workable. I have long wondered why information theory has not yet become more commonly used by others composing with computers. Perhaps this article will help to inspire more exploration of its few very basic but extremely powerful principles. 

_______________________________________________________   
1. Pierce, John R., Symbols, Signals and Noise: The Nature and Process of Communication (New York: Harper & Brothers, 1961), reprinted unabridged and revised as An Introduction to Information Theory: Symbols, Signals and Noise (New York: Dover Publications, 1980).

2. Shannon, Claude E., "A Mathematical Theory of Communication", Bell System Technical Journal (1948), reprinted in Shannon and Weaver, The Mathematical Theory of Communication (Univ. of Illinois Press, 1949).

3. Shannon, Claude E., "Communications in the Presence of Noise", Proceedings of the Institute of Radio Engineers, Vol. 37, pp. 10-21 (1949).

4. Spiegel, Laurie, "Manipulations of Musical Patterns", Proceedings of the Symposium on Small Computers and the Arts, IEEE, pp. 19-22 (1981), or http://retiary.org/ls/writings/musical_manip.html.   
_______________________________________________________   
Composer Laurie Spiegel has been writing and using compositional algorithms since the early 1970s. Information about and examples of her work are available on the web at http://retiary.org/.

---

Copyright ©1997 Laurie Spiegel. All rights reserved.

---

_[Laurie Spiegel's Bell Labs page](https://web.archive.org/web/20220629181101/http://retiary.org/ls/btl/btl.html)_ | _[Laurie Spiegel's writings page](https://web.archive.org/web/20220629181101/http://retiary.org/ls/writings.html)_ | _[Laurie Spiegel's home page](https://web.archive.org/web/20220629181101/http://retiary.org/ls/index.html)_


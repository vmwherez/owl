{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 2023-07-07\n",
    "`6:55p`\n",
    "\n",
    "Maybe `*.ipynb` files are just another resource in this system, where PDF had been and then markdown became most relevant as a new way to do things.  \n",
    "\n",
    "*some scratch LaTeX*\n",
    "$$ f(x) = \\int_{-\\infty}^\\infty  \\hat f(\\xi)\\,e^{2 \\pi i \\xi x}  \\,d\\xi $$\n",
    "\n",
    "\n",
    "*a python snippet*\n",
    "```python\n",
    "\n",
    "def exampleFunction():\n",
    "  \"\"\" This is a docstring.\"\"\"\n",
    "  pass\n",
    "\n",
    "```\n",
    "\n",
    "Code snippets like this can actually run. The experience isn't quite as pristine for journalling but again maybe we find a way to move between resources better.\n",
    "\n",
    "Another example of different tools and resources would be PDF and GoodNotes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/neuml/txtai\n",
      "  Cloning https://github.com/neuml/txtai to /private/tmp/pip-req-build-rdisda5n\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neuml/txtai /private/tmp/pip-req-build-rdisda5n\n",
      "  Resolved https://github.com/neuml/txtai to commit 319a11cacfe8d707178b7054a181dbba524c31ba\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: faiss-cpu>=1.7.1.post2 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from txtai==5.6.0) (1.7.4)\n",
      "Requirement already satisfied: numpy>=1.18.4 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from txtai==5.6.0) (1.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Library/Python/3.8/site-packages (from txtai==5.6.0) (6.0)\n",
      "Collecting torch>=1.12.1 (from txtai==5.6.0)\n",
      "  Downloading torch-2.0.1-cp38-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.22.0 (from txtai==5.6.0)\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from torch>=1.12.1->txtai==5.6.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from torch>=1.12.1->txtai==5.6.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from torch>=1.12.1->txtai==5.6.0) (1.12)\n",
      "Collecting networkx (from torch>=1.12.1->txtai==5.6.0)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Library/Python/3.8/site-packages (from torch>=1.12.1->txtai==5.6.0) (3.0.3)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.22.0->txtai==5.6.0)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Library/Python/3.8/site-packages (from transformers>=4.22.0->txtai==5.6.0) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from transformers>=4.22.0->txtai==5.6.0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from transformers>=4.22.0->txtai==5.6.0) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.22.0->txtai==5.6.0)\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.22.0->txtai==5.6.0)\n",
      "  Downloading safetensors-0.3.1-cp38-cp38-macosx_10_11_x86_64.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from transformers>=4.22.0->txtai==5.6.0) (4.65.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers>=4.22.0->txtai==5.6.0)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Python/3.8/site-packages (from packaging>=20.0->transformers>=4.22.0->txtai==5.6.0) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from jinja2->torch>=1.12.1->txtai==5.6.0) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Python/3.8/site-packages (from requests->transformers>=4.22.0->txtai==5.6.0) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Python/3.8/site-packages (from requests->transformers>=4.22.0->txtai==5.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Python/3.8/site-packages (from requests->transformers>=4.22.0->txtai==5.6.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Python/3.8/site-packages (from requests->transformers>=4.22.0->txtai==5.6.0) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mvm/Library/Python/3.8/lib/python/site-packages (from sympy->torch>=1.12.1->txtai==5.6.0) (1.3.0)\n",
      "Building wheels for collected packages: txtai\n",
      "  Building wheel for txtai (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for txtai: filename=txtai-5.6.0-py3-none-any.whl size=174477 sha256=722ed4b57fddf923dba5eaeb30fe780c1aebfad33ed8a64528dd3c138a82c9e7\n",
      "  Stored in directory: /private/tmp/pip-ephem-wheel-cache-pj5mkmgq/wheels/10/2f/69/334e42280faec2afdbea71215e11e9587d9a95834e527de137\n",
      "Successfully built txtai\n",
      "Installing collected packages: tokenizers, safetensors, networkx, fsspec, torch, huggingface-hub, transformers, txtai\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 networkx-3.1 safetensors-0.3.1 tokenizers-0.13.3 torch-2.0.1 transformers-4.30.2 txtai-5.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/neuml/txtai\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mvm/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 214kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.22G/1.22G [00:49<00:00, 24.6MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 3.38kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 4.86MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 14.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from txtai.pipeline import Summary\n",
    "\n",
    "# Create summary model\n",
    "summary = Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plan 9 is the failed1 successor to Unix. Many features that are common today in many Unix systems came from Plan 9. For example, the /proc file system was first implemented in'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "Plan 9 is the failed1 successor to Unix. It was developed by the same group, Bell Labs, with all of the experience they had gather in the twenty years since Unix was first written. Many features that are common today in many Unix systems, and some non Unix systems, came originally from Plan 9. For example, the /proc file system was first implemented in UNIX 8th Edition, which was the predecessor to Plan 92. Another example, which I will talk about in this post, is the use of process namespaces.\n",
    "\"\"\"\n",
    "\n",
    "summary(text, maxlength=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
